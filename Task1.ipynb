{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<span style=\"color:red\">Imports</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Other supported backends: tensorflow.compat.v1, tensorflow, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    }
   ],
   "source": [
    "# Math\n",
    "import math\n",
    "\n",
    "# Handy arrays\n",
    "import numpy as np\n",
    "\n",
    "# DeepXDE\n",
    "import deepxde as dde\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">**Постановка**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"var-07.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">**PINN**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange\">**Init**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span>**Функция вычисления невязок**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde(domain: torch.Tensor, u: torch.Tensor) -> torch.Tensor:\n",
    "    print(\"pde\")\n",
    "    # d^2 u\n",
    "    # -----\n",
    "    # dx ^2\n",
    "    du_xx = dde.grad.hessian(u, domain, i=0, j=0)\n",
    "\n",
    "    # d^2 u\n",
    "    # -----\n",
    "    # dy ^2\n",
    "    du_yy = dde.grad.hessian(u, domain, i=1, j=1)\n",
    "\n",
    "    # du/dt\n",
    "    du_t = dde.grad.jacobian(u, domain, j=2)\n",
    "\n",
    "    # Equation\n",
    "    return (du_t - 2.3 * (du_xx + du_yy)\n",
    "            - 2.5586 * torch.exp(-0.7 * domain[:, 2]) * torch.sin(0.9 * domain[:, 0])\n",
    "            - 13.5616 * torch.exp(-0.7 * domain[:, 2]) * torch.cos(2.2 * domain[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span>**Геометрия**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boundaries\n",
    "x_left, x_right = 0, math.pi\n",
    "y_down, y_up = -math.pi, math.pi\n",
    "T0, T1 = 0, 1\n",
    "\n",
    "# X & Y geomentry (rectangle)\n",
    "geometry = dde.geometry.Rectangle(xmin=[x_left, y_down], xmax=[x_right, y_up])\n",
    "# Time segment [0, 1]\n",
    "time_domain = dde.geometry.TimeDomain(T0, T1)\n",
    "# Final domain\n",
    "domain = dde.geometry.GeometryXTime(geometry, time_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span>**Функции принадлежности точки границе**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left boundary\n",
    "def l_boundary(domain, on_boundary):\n",
    "    return on_boundary and dde.utils.isclose(domain[0], x_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right boundary\n",
    "def r_boundary(domain, on_boundary):\n",
    "    return on_boundary and dde.utils.isclose(domain[0], x_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up boundary\n",
    "def up_boundary(domain, on_boundary):\n",
    "    return on_boundary and dde.utils.isclose(domain[1], y_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down boundary\n",
    "def down_boundary(domain, on_boundary):\n",
    "    return on_boundary and dde.utils.isclose(domain[1], y_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial boundary\n",
    "def initial_boundary(domain, on_initial):\n",
    "    return on_initial and dde.utils.isclose(domain[2], T0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span>**Граничные и начальные условия**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant to train\n",
    "c_lambda = dde.Variable(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boundary condition left\n",
    "def bc_l_func(domain):\n",
    "    # Get domain axis\n",
    "    x,y,t = domain\n",
    "\n",
    "    return 1.98 * torch.exp(-0.7 * t)\n",
    "\n",
    "bc_l = dde.NeumannBC(domain, bc_l_func, l_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boundary condition right\n",
    "def bc_r_func(domain):\n",
    "    # Get domain axis\n",
    "    x,y,t = domain\n",
    "    \n",
    "    return 1.3 + 1.3 * torch.exp(-0.7 * t) * torch.cos(2.2 * y) - 0.55 * (1 - math.sqrt(5)) * torch.exp(-0.7 * t)\n",
    "\n",
    "bc_r = dde.DirichletBC(domain, bc_r_func, r_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boundary condition up\n",
    "def bc_up_func(domain):\n",
    "    # Get domain axis\n",
    "    x,y,t = domain\n",
    "    \n",
    "    return -2.86 * math.sqrt(0.625 - math.sqrt(5)/8) * torch.exp(-0.7 * t)\n",
    "\n",
    "bc_up = dde.DirichletBC(domain, bc_up_func, up_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boundary condition down\n",
    "def bc_down_func(domain):\n",
    "    # Get domain axis\n",
    "    x,y,t = domain\n",
    "    \n",
    "    return 1.3 + 2.2 * torch.exp(-0.7 * t) * torch.sin(0.9 * x) + 0.875 * (1 + math.sqrt(5)) * torch.exp(-0.7 * t)\n",
    "\n",
    "bc_down = dde.NeumannBC(domain, bc_down_func, down_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial condition\n",
    "def ic_func(domain):\n",
    "    # Get domain axis\n",
    "    x,y,t = domain\n",
    "    \n",
    "    return c_lambda + 2.2 * torch.sin(0.9 * x) + 1.3 * torch.cos(2.2 * y)\n",
    "\n",
    "ic = dde.IC(domain, ic_func, initial_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed data\n",
    "data = np.load('var-07.npz')\n",
    "ob_domain = data['xyt']\n",
    "ob_u = data['u']\n",
    "observed_u = dde.icbc.PointSetBC(ob_domain, ob_u, component=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span>**Система уравнений**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 45 points required, but 50 points sampled.\n",
      "Warning: 100 points required, but 150 points sampled.\n"
     ]
    }
   ],
   "source": [
    "data = dde.data.TimePDE(domain, pde, [bc_l, bc_r, bc_up, bc_down, ic, observed_u],\n",
    "                        num_domain=10, num_boundary=10, num_initial=10,\n",
    "                        anchors=ob_domain,\n",
    "                        num_test=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span>**Нейронная сеть**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size = [3] + [50] * 2 + [1]\n",
    "\n",
    "net = dde.maps.FNN(layer_size, \"tanh\", \"Glorot uniform\")\n",
    "net.apply_output_transform(lambda x, y: abs(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span>**Обёртка нейронной сети**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "'compile' took 2.529178 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Epochs and batch size\n",
    "iterations = 1000\n",
    "batch_size = 16\n",
    "\n",
    "# Init and compile model\n",
    "model = dde.Model(data, net)\n",
    "model.compile(\"adam\", lr=1e-3, loss_weights=[1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checker = dde.callbacks.ModelCheckpoint(\n",
    "    \"model/model1.ckpt\", save_better_only=True, period=iterations/10\n",
    ")\n",
    "variable = dde.callbacks.VariableValue(c_lambda, period=iterations/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n",
      "pde\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 65.05 GiB. GPU 0 has a total capacity of 16.00 GiB of which 14.34 GiB is free. Of the allocated memory 496.33 MiB is allocated by PyTorch, and 25.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m losshistory, trainstate = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raakl\\.conda\\envs\\ml\\Lib\\site-packages\\deepxde\\utils\\internal.py:22\u001b[39m, in \u001b[36mtiming.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     21\u001b[39m     ts = timeit.default_timer()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     result = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     te = timeit.default_timer()\n\u001b[32m     24\u001b[39m     verbose = kwargs.get(\u001b[33m'\u001b[39m\u001b[33mverbose\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raakl\\.conda\\envs\\ml\\Lib\\site-packages\\deepxde\\model.py:673\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, iterations, batch_size, display_every, disregard_previous_best, callbacks, model_restore_path, model_save_path, epochs, verbose)\u001b[39m\n\u001b[32m    671\u001b[39m \u001b[38;5;28mself\u001b[39m.train_state.set_data_train(*\u001b[38;5;28mself\u001b[39m.data.train_next_batch(\u001b[38;5;28mself\u001b[39m.batch_size))\n\u001b[32m    672\u001b[39m \u001b[38;5;28mself\u001b[39m.train_state.set_data_test(*\u001b[38;5;28mself\u001b[39m.data.test())\n\u001b[32m--> \u001b[39m\u001b[32m673\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[38;5;28mself\u001b[39m.callbacks.on_train_begin()\n\u001b[32m    675\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m optimizers.is_external_optimizer(\u001b[38;5;28mself\u001b[39m.opt_name):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raakl\\.conda\\envs\\ml\\Lib\\site-packages\\deepxde\\model.py:866\u001b[39m, in \u001b[36mModel._test\u001b[39m\u001b[34m(self, verbose)\u001b[39m\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_test\u001b[39m(\u001b[38;5;28mself\u001b[39m, verbose=\u001b[32m1\u001b[39m):\n\u001b[32m    862\u001b[39m     \u001b[38;5;66;03m# TODO Now only print the training loss in rank 0. The correct way is to print the average training loss of all ranks.\u001b[39;00m\n\u001b[32m    863\u001b[39m     (\n\u001b[32m    864\u001b[39m         \u001b[38;5;28mself\u001b[39m.train_state.y_pred_train,\n\u001b[32m    865\u001b[39m         \u001b[38;5;28mself\u001b[39m.train_state.loss_train,\n\u001b[32m--> \u001b[39m\u001b[32m866\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_outputs_losses\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_aux_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    872\u001b[39m     \u001b[38;5;28mself\u001b[39m.train_state.y_pred_test, \u001b[38;5;28mself\u001b[39m.train_state.loss_test = \u001b[38;5;28mself\u001b[39m._outputs_losses(\n\u001b[32m    873\u001b[39m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    874\u001b[39m         \u001b[38;5;28mself\u001b[39m.train_state.X_test,\n\u001b[32m    875\u001b[39m         \u001b[38;5;28mself\u001b[39m.train_state.y_test,\n\u001b[32m    876\u001b[39m         \u001b[38;5;28mself\u001b[39m.train_state.test_aux_vars,\n\u001b[32m    877\u001b[39m     )\n\u001b[32m    879\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.train_state.y_test, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raakl\\.conda\\envs\\ml\\Lib\\site-packages\\deepxde\\model.py:579\u001b[39m, in \u001b[36mModel._outputs_losses\u001b[39m\u001b[34m(self, training, inputs, targets, auxiliary_vars)\u001b[39m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m backend_name == \u001b[33m\"\u001b[39m\u001b[33mpytorch\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28mself\u001b[39m.net.requires_grad_(requires_grad=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m     outs = \u001b[43moutputs_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauxiliary_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m     \u001b[38;5;28mself\u001b[39m.net.requires_grad_()\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m backend_name == \u001b[33m\"\u001b[39m\u001b[33mjax\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    582\u001b[39m     \u001b[38;5;66;03m# TODO: auxiliary_vars\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raakl\\.conda\\envs\\ml\\Lib\\site-packages\\deepxde\\model.py:325\u001b[39m, in \u001b[36mModel._compile_pytorch.<locals>.outputs_losses_train\u001b[39m\u001b[34m(inputs, targets, auxiliary_vars)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moutputs_losses_train\u001b[39m(inputs, targets, auxiliary_vars):\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moutputs_losses\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauxiliary_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlosses_train\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raakl\\.conda\\envs\\ml\\Lib\\site-packages\\deepxde\\model.py:313\u001b[39m, in \u001b[36mModel._compile_pytorch.<locals>.outputs_losses\u001b[39m\u001b[34m(training, inputs, targets, auxiliary_vars, losses_fn)\u001b[39m\n\u001b[32m    311\u001b[39m \u001b[38;5;66;03m# if forward-mode AD is used, then a forward call needs to be passed\u001b[39;00m\n\u001b[32m    312\u001b[39m aux = [\u001b[38;5;28mself\u001b[39m.net] \u001b[38;5;28;01mif\u001b[39;00m config.autodiff == \u001b[33m\"\u001b[39m\u001b[33mforward\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m losses = \u001b[43mlosses_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maux\u001b[49m\u001b[43m=\u001b[49m\u001b[43maux\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(losses, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    315\u001b[39m     losses = [losses]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raakl\\.conda\\envs\\ml\\Lib\\site-packages\\deepxde\\data\\data.py:13\u001b[39m, in \u001b[36mData.losses_train\u001b[39m\u001b[34m(self, targets, outputs, loss_fn, inputs, model, aux)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlosses_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, targets, outputs, loss_fn, inputs, model, aux=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     12\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a list of losses for training dataset, i.e., constraints.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maux\u001b[49m\u001b[43m=\u001b[49m\u001b[43maux\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raakl\\.conda\\envs\\ml\\Lib\\site-packages\\deepxde\\data\\pde.py:149\u001b[39m, in \u001b[36mPDE.losses\u001b[39m\u001b[34m(self, targets, outputs, loss_fn, inputs, model, aux)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pde \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m get_num_args(\u001b[38;5;28mself\u001b[39m.pde) == \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m         f = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpde\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs_pde\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m get_num_args(\u001b[38;5;28mself\u001b[39m.pde) == \u001b[32m3\u001b[39m:\n\u001b[32m    151\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auxiliary_var_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mpde\u001b[39m\u001b[34m(domain, u)\u001b[39m\n\u001b[32m     14\u001b[39m du_t = dde.grad.jacobian(u, domain, j=\u001b[32m2\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Equation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mdu_t\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2.3\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdu_xx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mdu_yy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2.5586\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msin\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m         - \u001b[32m13.5616\u001b[39m * torch.exp(-\u001b[32m0.7\u001b[39m * domain[:, \u001b[32m2\u001b[39m]) * torch.cos(\u001b[32m2.2\u001b[39m * domain[:, \u001b[32m1\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\raakl\\.conda\\envs\\ml\\Lib\\site-packages\\torch\\utils\\_device.py:104\u001b[39m, in \u001b[36mDeviceContext.__torch_function__\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs.get(\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.device\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 65.05 GiB. GPU 0 has a total capacity of 16.00 GiB of which 14.34 GiB is free. Of the allocated memory 496.33 MiB is allocated by PyTorch, and 25.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "losshistory, trainstate = model.train(iterations=iterations, callbacks = [variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish training with different optimizer\n",
    "model.compile(\"L-BFGS-B\")\n",
    "losshistory, train_state = model.train(iterations=iterations, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "'compile' took 0.000621 s\n",
      "\n",
      "Training model...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save training plot\n",
    "dde.saveplot(losshistory, trainstate, issave=True, isplot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
